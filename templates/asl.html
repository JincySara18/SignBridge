<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>SignBridge - ASL</title>
  <style>
    /* ... same styles as before (unchanged) ... */
  </style>
</head>
<body>
  <div class="container">
    <button class="back-btn" onclick="history.back()">â†</button>
    <button id="toggleCameraBtn">ğŸ” Switch Camera</button>

    <div id="video-wrapper">
      <video id="webcam" autoplay playsinline muted></video>
      <canvas id="overlay" width="640" height="500"></canvas>
    </div>

    <div class="prediction-box" id="prediction">No hand detected</div>

    <div class="speaker">
      <button onclick="speakPrediction()" aria-label="Speak Sign">
        <img id="speakerIcon" src="{{ url_for('static', filename='speaker.svg') }}" alt="Speaker Icon" />
      </button>
    </div>
  </div>

  <nav class="bottom-nav">
    <!-- bottom nav as before -->
  </nav>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <script>
    const videoElement = document.getElementById("webcam");
    const canvasElement = document.getElementById("overlay");
    const canvasCtx = canvasElement.getContext("2d");
    const predictionBox = document.getElementById("prediction");
    const toggleCameraBtn = document.getElementById("toggleCameraBtn");

    let useBackCamera = true;
    let currentStream = null;
    let currentPrediction = "No hand detected";
    let camera = null;

    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7,
    });

    hands.onResults((results) => {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const rawLandmarks = results.multiHandLandmarks[0];
        drawConnectors(canvasCtx, rawLandmarks, HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 2 });
        drawLandmarks(canvasCtx, rawLandmarks, { color: "#FF0000", radius: 3 });

        const [x, y] = [rawLandmarks[0].x * canvasElement.width, rawLandmarks[0].y * canvasElement.height];
        canvasCtx.font = "20px Arial";
        canvasCtx.fillStyle = "blue";
        canvasCtx.fillText(currentPrediction, x + 10, y - 10);

        predictSign(rawLandmarks);
      } else {
        predictionBox.textContent = "No hand detected";
      }

      canvasCtx.restore();
    });

    async function predictSign(landmarks) {
      const base = landmarks[0];
      const normalized = landmarks.flatMap((lm) => [lm.x - base.x, lm.y - base.y, lm.z - base.z]);
      const res = await fetch("/predict", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ landmarks: normalized }),
      });

      const data = await res.json();
      currentPrediction = data.prediction || "No hand detected";
      predictionBox.textContent = currentPrediction;
    }

    // âœ… NEW: Unlock camera labels before reading devices
    async function getAvailableCameras() {
      try {
        // Request camera access to get proper labels (iOS fix)
        await navigator.mediaDevices.getUserMedia({ video: true });
      } catch (e) {
        console.warn("Camera permission not yet granted.");
      }

      const devices = await navigator.mediaDevices.enumerateDevices();
      return devices.filter(device => device.kind === 'videoinput');
    }

    // âœ… NEW: Start camera using deviceId
    async function startCamera() {
      const videoDevices = await getAvailableCameras();
      if (videoDevices.length === 0) {
        alert("No camera found");
        return;
      }

      const backCamera = videoDevices.find(device =>
        device.label.toLowerCase().includes("back") || device.label.toLowerCase().includes("environment"));
      const frontCamera = videoDevices.find(device =>
        device.label.toLowerCase().includes("front") || device.label.toLowerCase().includes("user"));

      const selectedDevice = useBackCamera && backCamera ? backCamera : frontCamera || videoDevices[0];

      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }

      try {
        const constraints = {
          video: {
            deviceId: selectedDevice.deviceId,
            width: { ideal: 640 },
            height: { ideal: 480 }
          },
          audio: false
        };

        currentStream = await navigator.mediaDevices.getUserMedia(constraints);
        videoElement.srcObject = currentStream;

        videoElement.onloadedmetadata = () => {
          videoElement.play();
          canvasElement.width = videoElement.videoWidth;
          canvasElement.height = videoElement.videoHeight;

          if (camera) camera.stop();
          camera = new Camera(videoElement, {
            onFrame: async () => {
              await hands.send({ image: videoElement });
            },
            width: videoElement.videoWidth,
            height: videoElement.videoHeight,
          });

          camera.start();
        };
      } catch (err) {
        console.error("Camera error:", err);
        alert("Unable to access camera: " + err.message);
      }
    }

    toggleCameraBtn.addEventListener("click", () => {
      useBackCamera = !useBackCamera;
      startCamera();
    });

    window.addEventListener("DOMContentLoaded", () => {
      startCamera();
    });

    function speakPrediction() {
      if (!currentPrediction || currentPrediction === "No hand detected") return;
      const speakerIcon = document.getElementById("speakerIcon");
      speakerIcon.src = "/static/speaking.svg";
      const utterance = new SpeechSynthesisUtterance(currentPrediction);
      utterance.lang = "en-US";
      utterance.onend = () => speakerIcon.src = "/static/speaker.svg";
      utterance.onerror = (err) => console.error("Speech error:", err);
      speechSynthesis.cancel();
      speechSynthesis.speak(utterance);
    }
  </script>
</body>
</html>
